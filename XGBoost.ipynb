{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e72fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa29bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       clean_comment  category\n",
      "0   family mormon have never tried explain them t...         1\n",
      "1  buddhism has very much lot compatible with chr...         1\n",
      "2  seriously don say thing first all they won get...        -1\n",
      "3  what you have learned yours and only yours wha...         0\n",
      "4  for your own benefit you may want read living ...         1\n"
     ]
    }
   ],
   "source": [
    "# Assuming the dataset is named 'reddit_data.csv'\n",
    "df = pd.read_csv(r\"C:\\Users\\rohit\\Downloads\\archive\\Reddit_Data.csv\")\n",
    "\n",
    "# Check the first few rows to ensure data is loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a83b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'clean_comment' is NaN\n",
    "df = df.dropna(subset=['clean_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a05bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X = df['clean_comment']\n",
    "y = df['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88575a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data into TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to 5000 most frequent words\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c84d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c185de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:59:24] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b469c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = xgb_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c15b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8399730820995962\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.61      0.72      1597\n",
      "           0       0.81      0.96      0.88      2654\n",
      "           1       0.86      0.85      0.86      3179\n",
      "\n",
      "    accuracy                           0.84      7430\n",
      "   macro avg       0.85      0.81      0.82      7430\n",
      "weighted avg       0.84      0.84      0.83      7430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
